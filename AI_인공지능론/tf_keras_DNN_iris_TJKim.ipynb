{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "tf.keras_DNN_iris_TJKim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekdh_wnkIjDz"
      },
      "source": [
        "# google drive를 google colab에 연결. 처음 실행 시, 인증 필요\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22UZuhWkLtVt"
      },
      "source": [
        "#모듈(변수나 함수를 포함)만 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers  \n",
        "\n",
        "# iris 데이터를 읽어 들이고 정규화하기\n",
        "dir = \"/content/gdrive/My Drive/Colab Notebooks/ai/\"\n",
        "df = pd.read_csv(dir + \"iris.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GAFF1QOk58E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "db5cffa2-253a-4335-ba90-40c2e44d7c92"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>iris_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.5</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>2.2</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.1</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>7.2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width        iris_type\n",
              "0             6.4          3.1           5.5          1.8   Iris-virginica\n",
              "1             6.5          3.0           5.8          2.2   Iris-virginica\n",
              "2             4.6          3.1           1.5          0.2      Iris-setosa\n",
              "3             6.4          2.8           5.6          2.1   Iris-virginica\n",
              "4             5.0          3.3           1.4          0.2      Iris-setosa\n",
              "..            ...          ...           ...          ...              ...\n",
              "145           5.1          3.8           1.9          0.4      Iris-setosa\n",
              "146           5.7          2.8           4.5          1.3  Iris-versicolor\n",
              "147           6.9          3.1           5.4          2.1   Iris-virginica\n",
              "148           7.2          3.0           5.8          1.6   Iris-virginica\n",
              "149           4.9          3.0           1.4          0.2      Iris-setosa\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaC6EJH_kwwz"
      },
      "source": [
        "X = df.iloc[:,0:4]\n",
        "\n",
        "# 레이블 (labeling) onehot-encoding기법\n",
        "bclass = {\"Iris-setosa\":[1,0,0], \"Iris-versicolor\":[0,1,0], \"Iris-virginica\":[0,0,1]}\n",
        "y = np.empty((150,3))     \n",
        "for i, v in enumerate(df[\"iris_type\"]):\n",
        "  y[i] = bclass[v]        \n",
        "#\"iris-setosa'이면, y[i]=[1,0,0] 와 같이 할당\n",
        "    \n",
        "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기\n",
        "X_train, y_train = X[0:100], y[0:100]\n",
        "X_test,  y_test  = X[101:150], y[101:150]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "G2UgYhccLtVu"
      },
      "source": [
        "# 모델 구조 정의하기\n",
        "model = tf.keras.Sequential()  \n",
        "model.add(layers.Dense(16, input_shape=(4,))) \n",
        "model.add(layers.Activation('relu')) \n",
        "model.add(layers.Dropout(0.05))      \n",
        "\n",
        "model.add(layers.Dense(8))       \n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "\n",
        "model.add(layers.Dense(3))\n",
        "model.add(layers.Activation('softmax'))\n",
        "\n",
        "# 모델 구축하기\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer=\"rmsprop\",  \n",
        "    metrics=['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2IhHchdXLtVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a62142-bb33-43b1-a82b-fef9bd685c76"
      },
      "source": [
        "# 데이터 훈련하기\n",
        "hist = model.fit( X_train, y_train, batch_size=5, epochs=300, validation_split=0.2,  \n",
        "      #callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)],\n",
        "      verbose=1) \n",
        "\n",
        "# 테스트 데이터로 평가하기\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('test_loss: ', score[0])\n",
        "print('test_acc: ', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 1.1801 - accuracy: 0.4250 - val_loss: 0.9634 - val_accuracy: 0.6000\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9923 - accuracy: 0.5250 - val_loss: 0.9145 - val_accuracy: 0.7500\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9661 - accuracy: 0.7000 - val_loss: 0.8831 - val_accuracy: 0.8500\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9547 - accuracy: 0.7625 - val_loss: 0.8525 - val_accuracy: 0.9000\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.8665 - accuracy: 0.8375 - val_loss: 0.8307 - val_accuracy: 1.0000\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8723 - accuracy: 0.8125 - val_loss: 0.8065 - val_accuracy: 1.0000\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8902 - accuracy: 0.7375 - val_loss: 0.7651 - val_accuracy: 1.0000\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8821 - accuracy: 0.7375 - val_loss: 0.7310 - val_accuracy: 1.0000\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7967 - accuracy: 0.8250 - val_loss: 0.6868 - val_accuracy: 1.0000\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.8375 - val_loss: 0.6475 - val_accuracy: 1.0000\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.8500 - val_loss: 0.6132 - val_accuracy: 1.0000\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.8125 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.8375 - val_loss: 0.5399 - val_accuracy: 1.0000\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.8625 - val_loss: 0.5013 - val_accuracy: 1.0000\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.8500 - val_loss: 0.4695 - val_accuracy: 1.0000\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.8250 - val_loss: 0.4412 - val_accuracy: 1.0000\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.8750 - val_loss: 0.4157 - val_accuracy: 1.0000\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7875 - val_loss: 0.3999 - val_accuracy: 1.0000\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.8750 - val_loss: 0.3630 - val_accuracy: 1.0000\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.8625 - val_loss: 0.3410 - val_accuracy: 1.0000\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8875 - val_loss: 0.3215 - val_accuracy: 1.0000\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8375 - val_loss: 0.3082 - val_accuracy: 1.0000\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.8625 - val_loss: 0.2941 - val_accuracy: 1.0000\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.9250 - val_loss: 0.2788 - val_accuracy: 1.0000\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8875 - val_loss: 0.2506 - val_accuracy: 1.0000\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.9000 - val_loss: 0.2347 - val_accuracy: 1.0000\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.8875 - val_loss: 0.2200 - val_accuracy: 1.0000\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8875 - val_loss: 0.2127 - val_accuracy: 1.0000\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.9125 - val_loss: 0.1945 - val_accuracy: 1.0000\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.9125 - val_loss: 0.1845 - val_accuracy: 1.0000\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8875 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8875 - val_loss: 0.1733 - val_accuracy: 1.0000\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.9250 - val_loss: 0.1686 - val_accuracy: 1.0000\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.9250 - val_loss: 0.1527 - val_accuracy: 1.0000\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8750 - val_loss: 0.1466 - val_accuracy: 1.0000\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.9250 - val_loss: 0.1408 - val_accuracy: 1.0000\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9250 - val_loss: 0.1354 - val_accuracy: 1.0000\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.9125 - val_loss: 0.1378 - val_accuracy: 1.0000\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9500 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.9250 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9250 - val_loss: 0.1092 - val_accuracy: 1.0000\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 0.8875 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.9125 - val_loss: 0.1053 - val_accuracy: 1.0000\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1953 - accuracy: 0.9625 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.8875 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8625 - val_loss: 0.0982 - val_accuracy: 1.0000\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9500 - val_loss: 0.0931 - val_accuracy: 1.0000\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9250 - val_loss: 0.0885 - val_accuracy: 1.0000\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9125 - val_loss: 0.0916 - val_accuracy: 1.0000\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2635 - accuracy: 0.9000 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9625 - val_loss: 0.0899 - val_accuracy: 1.0000\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9000 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9000 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.9000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9250 - val_loss: 0.0825 - val_accuracy: 1.0000\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1977 - accuracy: 0.9000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9625 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9125 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1896 - accuracy: 0.9375 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9500 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2248 - accuracy: 0.9500 - val_loss: 0.0605 - val_accuracy: 1.0000\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9375 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9750 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9250 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9375 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9375 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.8875 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9125 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9500 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9375 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9375 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1972 - accuracy: 0.9500 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.9250 - val_loss: 0.0448 - val_accuracy: 1.0000\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9375 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9125 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9375 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9625 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9375 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9250 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9625 - val_loss: 0.0687 - val_accuracy: 0.9500\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9375 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9250 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9500 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9625 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9375 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9125 - val_loss: 0.0658 - val_accuracy: 0.9500\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9500 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9625 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9750 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9625 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1445 - accuracy: 0.9625 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9250 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9375 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9250 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9125 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9125 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9875 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9250 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9375 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9500 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9500 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9250 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9250 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9625 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9625 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9750 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9500 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9375 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9500 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9125 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9375 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9500 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9500 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9500 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9625 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.2090 - accuracy: 0.8875 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9375 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9500 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9375 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9750 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9375 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9500 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9500 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9500 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9500 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9500 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9250 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9500 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9375 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9750 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9625 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9625 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9375 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9625 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9875 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9625 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9625 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9500 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9375 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9375 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9500 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9500 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9625 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9625 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.9125 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9625 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9375 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9500 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9375 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9500 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9750 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9625 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9875 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9375 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9750 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9500 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9625 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9500 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9750 - val_loss: 0.0466 - val_accuracy: 0.9500\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9500 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9375 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9750 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9750 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9625 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9375 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9250 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9625 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9500 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9625 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9375 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9500 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9750 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9500 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9625 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9500 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9875 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9625 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1419 - accuracy: 0.9375 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9375 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9625 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9500 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9500 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.9625 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9750 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9750 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9500 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9750 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.9625 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9500 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9750 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9625 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9625 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9750 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9750 - val_loss: 0.0522 - val_accuracy: 0.9500\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.9375 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9625 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9875 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9500 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9625 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9500 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9375 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9375 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9625 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9750 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9625 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9250 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9750 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9750 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9250 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1323 - accuracy: 0.9500 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1645 - accuracy: 0.9250 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9875 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9375 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9875 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9750 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9625 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9750 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9875 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9625 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9750 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9625 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9875 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9875 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9500 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9625 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9500 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1395 - accuracy: 0.9625 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9125 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9500 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9500 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9625 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.9625 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9750 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9625 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9250 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9625 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9875 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9500 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9625 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9375 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9625 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9625 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9750 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9375 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9375 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9750 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9500 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.9750 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9500 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9500 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9375 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9500 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9875 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9625 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9375 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9625 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9500 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9500 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9750 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9250 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9500 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9625 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9750 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9750 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9625 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9875 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9625 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9500 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9625 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9500 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9750 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9750 - val_loss: 0.0419 - val_accuracy: 0.9500\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.9625 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9500 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9750 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9875 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9625 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9750 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9625 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9500 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9875 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9625 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9750 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9375 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9750 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9500 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9625 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9500 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0913 - accuracy: 0.9500 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9750 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9375 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9625 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9796\n",
            "test_loss:  0.043233998119831085\n",
            "test_acc:  0.9795918464660645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVZ2sf6Gb5Y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47b48c3-84ac-40be-c63d-91b928d259cd"
      },
      "source": [
        "hist.history.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hh1NwcAwLtVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "dd6b72f8-9039-4ea5-c7bc-b4a12ceb42ec"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0LNN770LtVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1da177c-9f81-4d36-c5f9-74d60658fcb6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                80        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 27        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 243\n",
            "Trainable params: 243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap06VxZI5Aog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7705dab0-4fbe-40b3-c89f-add668ae951b"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.07024505, -0.31196666, -0.30865902, -0.0595131 , -0.3471586 ,\n",
              "          0.15852566,  0.26915276, -0.47061747, -0.2844568 ,  0.29970753,\n",
              "          0.13255024, -0.03408131,  0.40736634, -0.31909275, -0.35506448,\n",
              "         -0.26891464],\n",
              "        [-0.39631405,  0.09553421,  0.32443577, -0.23512645,  0.22775106,\n",
              "         -0.26499057,  0.18898487, -0.5414001 ,  0.02344451, -0.37339777,\n",
              "         -0.5259195 ,  0.7030973 ,  0.10171921, -0.16057447, -0.43802786,\n",
              "         -0.05623099],\n",
              "        [ 0.26917467,  0.04101181, -0.01170939,  0.43688646,  0.3518328 ,\n",
              "          0.02560802,  0.07062239,  0.37145603,  0.35025215, -0.502278  ,\n",
              "         -0.25200948, -0.29255268, -0.60029304,  0.35923898,  0.5522235 ,\n",
              "         -0.0238207 ],\n",
              "        [-0.08779056, -0.3553621 ,  0.35475928,  0.34667584,  0.44132072,\n",
              "          0.787394  ,  0.37047073, -0.36275515,  0.16991618, -0.14995149,\n",
              "         -0.06998301, -0.28826496, -0.02919878,  0.65743965,  0.6769518 ,\n",
              "         -0.42416745]], dtype=float32),\n",
              " array([-0.00842201,  0.        ,  0.        , -0.007951  , -0.15281934,\n",
              "        -0.23395878,  0.06649107,  0.        , -0.13161653,  0.        ,\n",
              "         0.        ,  0.13951147,  0.25076658, -0.19934611, -0.13877814,\n",
              "         0.        ], dtype=float32),\n",
              " array([[-0.49101347,  0.02061069, -0.2912991 , -0.3952313 ,  0.44795585,\n",
              "          0.09701884,  0.27120185,  0.42799616],\n",
              "        [ 0.20529926,  0.25545692,  0.27865076, -0.18256211, -0.4315002 ,\n",
              "         -0.0456115 ,  0.2575239 ,  0.43552113],\n",
              "        [-0.28207588, -0.27307498, -0.03730166, -0.07247829, -0.40673542,\n",
              "          0.4062277 ,  0.11583722, -0.2573868 ],\n",
              "        [-0.11774834, -0.8176895 , -0.10721634,  0.04444198, -0.18903685,\n",
              "         -0.3287158 ,  1.179395  ,  0.19942044],\n",
              "        [ 0.1731476 , -0.9420774 , -0.3910391 , -0.08235023, -0.41449067,\n",
              "         -0.36024344,  1.2676741 , -0.09165455],\n",
              "        [ 0.11980445, -0.48964474,  0.5458809 ,  0.3256134 ,  0.39738393,\n",
              "         -0.23398428,  1.214871  ,  0.01454003],\n",
              "        [ 0.09797325, -0.01890755,  0.30325112, -0.00411128, -0.2733245 ,\n",
              "          0.32952374,  0.08477123, -0.07291306],\n",
              "        [-0.31083977, -0.4696939 ,  0.18150914, -0.35214734,  0.39838266,\n",
              "          0.04080427,  0.00860107,  0.45960987],\n",
              "        [ 0.74158585, -0.06184723, -0.7137277 ,  0.13803655, -0.13799469,\n",
              "         -0.54756844,  1.0698771 , -0.1534715 ],\n",
              "        [ 0.32352066, -0.1510694 ,  0.33779728,  0.13259983, -0.18339431,\n",
              "         -0.33899975, -0.3826841 ,  0.3928125 ],\n",
              "        [-0.09112847, -0.42798305,  0.38036573, -0.2506795 , -0.36063945,\n",
              "         -0.436746  ,  0.1929189 ,  0.48958886],\n",
              "        [-1.0034075 ,  0.8349225 , -0.38894066, -1.1527593 , -0.4450821 ,\n",
              "          1.7520494 , -0.43428025,  0.5039521 ],\n",
              "        [-0.21644427,  0.8578667 , -0.06763877, -0.45948458, -0.34304187,\n",
              "          1.3088608 , -0.07153562,  0.655832  ],\n",
              "        [ 0.93642634, -0.44918856, -0.93378806,  0.64680815, -0.04143628,\n",
              "         -0.3076348 ,  0.6841649 , -0.52232975],\n",
              "        [ 0.66643095,  0.0309484 , -0.71092284,  0.8761701 , -0.4622381 ,\n",
              "         -0.9058998 ,  1.2424737 , -0.63450885],\n",
              "        [ 0.4275322 ,  0.38650262,  0.31956625,  0.01590931, -0.34351826,\n",
              "         -0.20287943, -0.4854597 , -0.22146308]], dtype=float32),\n",
              " array([-0.27153727,  0.16842128,  0.14025475, -0.2422027 , -0.04179835,\n",
              "         0.3692019 ,  0.17549296,  0.27854922], dtype=float32),\n",
              " array([[-1.6105053 , -0.92141765,  0.8672567 ],\n",
              "        [ 1.4017518 , -1.4540244 , -0.8732585 ],\n",
              "        [-1.267817  ,  0.6269002 , -0.21076037],\n",
              "        [-0.9519681 , -0.6861004 ,  1.043949  ],\n",
              "        [-0.11171816, -0.12470563,  0.48453915],\n",
              "        [ 0.5096096 , -0.16537547, -2.2449107 ],\n",
              "        [-2.1618805 , -0.4604784 , -0.3529023 ],\n",
              "        [ 0.45626432,  0.8957757 , -1.1514814 ]], dtype=float32),\n",
              " array([-0.42756653,  0.37741968, -0.26815993], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nhPK4V6nLtVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802f5cac-22e8-4794-bf81-7ba9ef745537"
      },
      "source": [
        "model.save(dir+\"dnn_iris.h5\")\n",
        "print(\"Saved model to disk.\")\n",
        "\n",
        "#load and evaluate the saved model\n",
        "from numpy import loadtxt\n",
        "from tensorflow.python.keras.models import load_model\n",
        "\n",
        "#load model\n",
        "loaded_model = load_model(dir+\"dnn_iris.h5\")\n",
        "model.summary()\n",
        "\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('test_loss: ', score[0])\n",
        "print('test_acc: ', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                80        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 27        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 243\n",
            "Trainable params: 243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9796\n",
            "test_loss:  0.043233998119831085\n",
            "test_acc:  0.9795918464660645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8sQr21XLtVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33b42f2-fdbf-4d3b-f925-fa47ad8afcf8"
      },
      "source": [
        "# X_test의 예측 클래스 확인하기\n",
        "y_prob = model.predict(X_test)  # output node의 출력값 확인하기\n",
        "print(y_prob)\n",
        "\n",
        "y_class = y_prob.argmax(axis=-1)  # output node의 예측값(class) 확인하기\n",
        "y_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.2167060e-12 1.3503967e-03 9.9864966e-01]\n",
            " [1.6019867e-09 8.4399786e-03 9.9156004e-01]\n",
            " [2.5842572e-03 9.9623352e-01 1.1822472e-03]\n",
            " [6.9436963e-11 6.1680335e-03 9.9383199e-01]\n",
            " [9.9999547e-01 4.4944868e-06 8.4986847e-14]\n",
            " [9.9999821e-01 1.8370620e-06 1.2097677e-14]\n",
            " [9.9999976e-01 2.6454452e-07 1.5064543e-16]\n",
            " [7.4707991e-08 5.3422332e-02 9.4657755e-01]\n",
            " [7.7924844e-10 1.2937548e-02 9.8706239e-01]\n",
            " [3.5507299e-05 9.8253709e-01 1.7427383e-02]\n",
            " [9.9999750e-01 2.4797448e-06 2.2104151e-14]\n",
            " [2.3184922e-04 9.9675852e-01 3.0096744e-03]\n",
            " [9.9999976e-01 2.8420055e-07 1.6201587e-16]\n",
            " [2.7302920e-05 9.9305987e-01 6.9128522e-03]\n",
            " [9.7751478e-09 4.8572369e-02 9.5142764e-01]\n",
            " [2.1922483e-10 2.5147973e-03 9.9748516e-01]\n",
            " [3.4849194e-04 9.9883908e-01 8.1241014e-04]\n",
            " [3.0209412e-04 9.9712557e-01 2.5723428e-03]\n",
            " [9.9999595e-01 4.0753180e-06 6.8968635e-14]\n",
            " [9.9998665e-01 1.3297116e-05 9.5360221e-13]\n",
            " [9.9999201e-01 7.9424299e-06 3.0511111e-13]\n",
            " [1.9381939e-11 1.4676752e-03 9.9853230e-01]\n",
            " [9.8494306e-09 2.9509054e-02 9.7049093e-01]\n",
            " [1.1532185e-09 1.3988582e-02 9.8601139e-01]\n",
            " [9.9997282e-01 2.7163353e-05 5.0338705e-12]\n",
            " [1.3760373e-04 9.9891984e-01 9.4256352e-04]\n",
            " [5.0412281e-14 1.3904297e-04 9.9986088e-01]\n",
            " [3.8582736e-04 9.9773252e-01 1.8815742e-03]\n",
            " [9.9999964e-01 3.8401092e-07 3.3291846e-16]\n",
            " [2.5300984e-05 8.4432471e-01 1.5565008e-01]\n",
            " [7.7910474e-05 9.6360493e-01 3.6317136e-02]\n",
            " [9.9964714e-01 3.5290245e-04 5.7105642e-10]\n",
            " [9.9999917e-01 8.9355706e-07 2.2325864e-15]\n",
            " [2.1917793e-07 1.6269392e-01 8.3730584e-01]\n",
            " [1.5747356e-06 4.3236530e-01 5.6763309e-01]\n",
            " [5.3531450e-11 4.3552183e-03 9.9564481e-01]\n",
            " [3.9744694e-07 1.9089162e-01 8.0910796e-01]\n",
            " [1.1500154e-09 5.3890636e-03 9.9461091e-01]\n",
            " [1.3852190e-08 1.1629435e-01 8.8370568e-01]\n",
            " [3.9730333e-12 5.2775926e-04 9.9947220e-01]\n",
            " [9.9998128e-01 1.8706418e-05 2.0468165e-12]\n",
            " [1.2148395e-03 9.9848443e-01 3.0077176e-04]\n",
            " [5.5239086e-10 8.0342749e-03 9.9196577e-01]\n",
            " [2.9303472e-05 9.9627197e-01 3.6986950e-03]\n",
            " [9.9999094e-01 9.0728490e-06 3.6073789e-13]\n",
            " [6.7590525e-05 9.7837752e-01 2.1554779e-02]\n",
            " [5.3632214e-09 3.8457792e-02 9.6154225e-01]\n",
            " [1.6658737e-07 2.2479136e-01 7.7520853e-01]\n",
            " [9.9997842e-01 2.1527832e-05 2.5940179e-12]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 2, 0, 0, 0, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2,\n",
              "       2, 2, 0, 1, 2, 1, 0, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 1,\n",
              "       0, 1, 2, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Xez1yYLtV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9618e4-0ee4-43a8-a4ac-cf6369eb9fbf"
      },
      "source": [
        "# 새로운 샘플의 예측 클래스 확인하기\n",
        "X_new = [5.7, 3.8, 1.7, 0.3]\n",
        "print(X_new)\n",
        "\n",
        "y_prob = model.predict([X_new])\n",
        "y_pred = y_prob.argmax()\n",
        "print(y_prob, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.7, 3.8, 1.7, 0.3]\n",
            "[[9.9999774e-01 2.2759980e-06 1.7504949e-14]] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDjOYxUzLtVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e4a1eb-d604-4407-c2fe-1dfb663d00c2"
      },
      "source": [
        "type(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOdX9FRmLtVz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "537ae9fb-2879-4c60-88de-bbc5a3507554"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>7.2</td>\n",
              "      <td>3.6</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>5.6</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>7.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width\n",
              "101           7.2          3.6           6.1          2.5\n",
              "102           6.3          2.9           5.6          1.8\n",
              "103           4.9          2.4           3.3          1.0\n",
              "104           7.7          3.0           6.1          2.3\n",
              "105           5.1          3.5           1.4          0.3"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaOIG8Kaovrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d887999-38e1-426a-af12-09d2488d5504"
      },
      "source": [
        "X_test.head(5).index.tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 102, 103, 104, 105]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfXV29CxuGk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca16878d-d4b9-48a1-9bb1-c1e167dea7a4"
      },
      "source": [
        "X_test0 = X_test.loc[101]\n",
        "print(X_test0); print()\n",
        "\n",
        "X_test_li = list(X_test0)\n",
        "y_prob = model.predict([X_test_li])  # model.predict([[0.69, 0.55]])\n",
        "y_pred = y_prob.argmax()\n",
        "print(y_prob, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal_length    7.2\n",
            "sepal_width     3.6\n",
            "petal_length    6.1\n",
            "petal_width     2.5\n",
            "Name: 101, dtype: float64\n",
            "\n",
            "[[2.1815294e-13 1.3714611e-02 9.8628545e-01]] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flB-FoC2LtV0"
      },
      "source": [
        "def predict_iris(X_new):\n",
        "  y_prob = model.predict([X_new])\n",
        "  y_pred = y_prob.argmax()\n",
        "  print(X_new, y_prob, y_pred, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMJdeu5nLtV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be6da8c-d3a6-4af7-c3a3-3ba15b356e41"
      },
      "source": [
        "X_mean = [X_train[\"sepal_length\"].mean(), X_train[\"sepal_width\"].mean(), X_train[\"petal_length\"].mean(), X_train[\"petal_width\"].mean()]\n",
        "X_min = [X_train[\"sepal_length\"].min(), X_train[\"sepal_width\"].min(), X_train[\"petal_length\"].min(), X_train[\"petal_width\"].min()]\n",
        "X_max = [X_train[\"sepal_length\"].max(), X_train[\"sepal_width\"].max(), X_train[\"petal_length\"].max(), X_train[\"petal_width\"].max()]\n",
        "\n",
        "predict_iris(X_mean)\n",
        "predict_iris(X_min)\n",
        "predict_iris(X_max)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.770000000000001, 3.019, 3.6839999999999997, 1.1649999999999998]\t[[5.9694797e-03 9.9402469e-01 5.8344895e-06]]\t1\n",
            "[4.3, 2.0, 1.1, 0.1]\t[[9.9765152e-01 2.3484777e-03 1.2090458e-11]]\t0\n",
            "[7.7, 4.1, 6.7, 2.5]\t[[8.3951597e-14 1.5300966e-02 9.8469907e-01]]\t2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5TzGhVk10MX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}